#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ASRè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆWER: Word Error Rateï¼‰

Whisperèªè­˜çµæœã®å“è³ªã‚’å®šé‡çš„ã«æŠŠæ¡ã—ã€
éŸ³å£°ãƒ†ã‚¹ãƒˆã®ã€ŒASRå“è³ªãƒã‚§ãƒƒã‚¯ã€ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python3 scripts/asr_eval.py
    python3 scripts/asr_eval.py --threshold 0.10
"""

import sys
import json
import os
from pathlib import Path
from typing import Dict, List, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’å–å¾—
PROJECT_ROOT = Path(__file__).resolve().parent.parent
TTS_TEST_DIR = PROJECT_ROOT / "tts_test"
EVAL_DIR = TTS_TEST_DIR / "results"
REFERENCE_FILE = TTS_TEST_DIR / "reference_texts.json"
OUTPUT_JSON = PROJECT_ROOT / "logs" / "asr_eval_results.json"

# WERè¨ˆç®—ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    from jiwer import wer, cer  # Word Error Rate, Character Error Rate
    JIWER_AVAILABLE = True
except ImportError:
    JIWER_AVAILABLE = False
    # ç°¡æ˜“ç‰ˆWERè¨ˆç®—ï¼ˆLevenshteinè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰
    try:
        from Levenshtein import distance as levenshtein_distance
        LEVENSHTEIN_AVAILABLE = True
    except ImportError:
        LEVENSHTEIN_AVAILABLE = False

def simple_wer(reference: str, hypothesis: str) -> float:
    """
    ç°¡æ˜“ç‰ˆWERè¨ˆç®—ï¼ˆLevenshteinè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰
    jiwerãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    if not LEVENSHTEIN_AVAILABLE:
        # æœ€ã‚‚ç°¡æ˜“ãªæ–¹æ³•ï¼šæ–‡å­—åˆ—ä¸€è‡´ç‡
        if not reference:
            return 1.0 if hypothesis else 0.0
        if not hypothesis:
            return 1.0
        
        ref_words = reference.split()
        hyp_words = hypothesis.split()
        
        if not ref_words:
            return 1.0 if hyp_words else 0.0
        if not hyp_words:
            return 1.0
        
        # å˜èªãƒ¬ãƒ™ãƒ«ã§ã®ç·¨é›†è·é›¢ã‚’è¿‘ä¼¼
        max_len = max(len(ref_words), len(hyp_words))
        if max_len == 0:
            return 0.0
        
        # ç°¡æ˜“ç‰ˆï¼šä¸€è‡´ã™ã‚‹å˜èªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        ref_set = set(ref_words)
        hyp_set = set(hyp_words)
        common = len(ref_set & hyp_set)
        total = len(ref_set | hyp_set)
        
        return 1.0 - (common / total) if total > 0 else 0.0
    
    # Levenshteinè·é›¢ã‚’ä½¿ç”¨
    ref_words = reference.split()
    hyp_words = hypothesis.split()
    
    if not ref_words:
        return 1.0 if hyp_words else 0.0
    if not hyp_words:
        return 1.0
    
    # å˜èªåˆ—ã®ç·¨é›†è·é›¢ã‚’è¨ˆç®—
    ref_str = " ".join(ref_words)
    hyp_str = " ".join(hyp_words)
    
    max_len = max(len(ref_str), len(hyp_str))
    if max_len == 0:
        return 0.0
    
    distance = levenshtein_distance(ref_str, hyp_str)
    return distance / max_len

def calculate_wer(reference: str, hypothesis: str) -> float:
    """
    WERï¼ˆWord Error Rateï¼‰ã‚’è¨ˆç®—
    
    :param reference: æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆ
    :param hypothesis: èªè­˜çµæœ
    :return: WERå€¤ï¼ˆ0.0ï½1.0ã€å°ã•ã„ã»ã©è‰¯ã„ï¼‰
    """
    if not reference and not hypothesis:
        return 0.0
    
    if JIWER_AVAILABLE:
        try:
            return wer(reference, hypothesis)
        except Exception as e:
            print(f"âš ï¸  jiwerè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return simple_wer(reference, hypothesis)
    else:
        return simple_wer(reference, hypothesis)

def load_reference_texts() -> Dict[str, str]:
    """
    æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
    
    :return: {ãƒ•ã‚¡ã‚¤ãƒ«å: æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆ} ã®è¾æ›¸
    """
    if not REFERENCE_FILE.exists():
        print(f"âš ï¸  è­¦å‘Š: æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {REFERENCE_FILE}")
        print("   ç©ºã®è¾æ›¸ã‚’è¿”ã—ã¾ã™ã€‚")
        return {}
    
    try:
        with open(REFERENCE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        return {}

def load_recognized_texts() -> Dict[str, str]:
    """
    èªè­˜çµæœã‚’èª­ã¿è¾¼ã‚€
    
    :return: {ãƒ•ã‚¡ã‚¤ãƒ«å: èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ} ã®è¾æ›¸
    """
    recognized = {}
    
    if not EVAL_DIR.exists():
        print(f"âš ï¸  è­¦å‘Š: è©•ä¾¡çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {EVAL_DIR}")
        return recognized
    
    # results/*.txt ã‚’èª­ã¿è¾¼ã‚€
    for txt_file in EVAL_DIR.glob("*.txt"):
        fname = txt_file.stem  # æ‹¡å¼µå­ã‚’é™¤ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å
        try:
            with open(txt_file, "r", encoding="utf-8") as f:
                recognized[fname] = f.read().strip()
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: {txt_file} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
    
    return recognized

def evaluate_asr(threshold: float = 0.10) -> Tuple[List[Dict], float, int]:
    """
    ASRè©•ä¾¡ã‚’å®Ÿè¡Œ
    
    :param threshold: åˆæ ¼ãƒ©ã‚¤ãƒ³ï¼ˆå¹³å‡WERï¼‰
    :return: (è©•ä¾¡çµæœãƒªã‚¹ãƒˆ, å¹³å‡WER, ã‚µãƒ³ãƒ—ãƒ«æ•°)
    """
    reference_texts = load_reference_texts()
    recognized_texts = load_recognized_texts()
    
    if not reference_texts:
        print("âŒ ã‚¨ãƒ©ãƒ¼: æœŸå¾…ãƒ†ã‚­ã‚¹ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print(f"   {REFERENCE_FILE} ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return [], 0.0, 0
    
    if not recognized_texts:
        print("âŒ ã‚¨ãƒ©ãƒ¼: èªè­˜çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"   {EVAL_DIR} ã«èªè­˜çµæœãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ*.txtï¼‰ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return [], 0.0, 0
    
    results = []
    total_wer = 0.0
    count = 0
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©•ä¾¡
    for fname, expected_text in reference_texts.items():
        if fname not in recognized_texts:
            print(f"âš ï¸  {fname}: èªè­˜çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            continue
        
        recognized = recognized_texts[fname]
        
        # èªè­˜çµæœã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã®æ•°å­—ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ï¼ˆä¾‹: "004ã‚‚ã—ã‚‚ã—" â†’ "ã‚‚ã—ã‚‚ã—"ï¼‰
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒæ•°å­—ã§å§‹ã¾ã‚‹å ´åˆã€èªè­˜çµæœã®å…ˆé ­ã«æ•°å­—ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        import re
        # å…ˆé ­ã®æ•°å­—ã‚’é™¤å»
        recognized_cleaned = re.sub(r'^\d+', '', recognized).strip()
        if not recognized_cleaned:
            recognized_cleaned = recognized
        
        wer_score = calculate_wer(expected_text, recognized_cleaned)
        
        results.append({
            "file": fname,
            "expected": expected_text,
            "recognized": recognized_cleaned,
            "wer": wer_score,
            "status": "PASS" if wer_score < threshold else "FAIL"
        })
        
        print(f"{fname}: {wer_score:.3f}")
        total_wer += wer_score
        count += 1
    
    avg_wer = total_wer / max(count, 1)
    
    return results, avg_wer, count

def save_results_json(results: List[Dict], avg_wer: float, count: int, threshold: float):
    """
    è©•ä¾¡çµæœã‚’JSONå½¢å¼ã§ä¿å­˜ï¼ˆWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ï¼‰
    
    :param results: è©•ä¾¡çµæœãƒªã‚¹ãƒˆ
    :param avg_wer: å¹³å‡WER
    :param count: ã‚µãƒ³ãƒ—ãƒ«æ•°
    :param threshold: åˆæ ¼ãƒ©ã‚¤ãƒ³
    """
    output_data = {
        "timestamp": __import__("datetime").datetime.now().isoformat(),
        "summary": {
            "total_samples": count,
            "avg_wer": avg_wer,
            "threshold": threshold,
            "status": "PASS" if avg_wer < threshold else "FAIL"
        },
        "results": results
    }
    
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    OUTPUT_JSON.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è©•ä¾¡çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {OUTPUT_JSON}")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: è©•ä¾¡çµæœã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ASRè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆWERè¨ˆç®—ï¼‰")
    parser.add_argument("--threshold", type=float, default=0.10, help="åˆæ ¼ãƒ©ã‚¤ãƒ³ï¼ˆå¹³å‡WERã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.10ï¼‰")
    parser.add_argument("--no-json", action="store_true", help="JSONå‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    args = parser.parse_args()
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
    if not JIWER_AVAILABLE and not LEVENSHTEIN_AVAILABLE:
        print("âš ï¸  è­¦å‘Š: jiwer ã¾ãŸã¯ python-Levenshtein ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("   ç°¡æ˜“ç‰ˆWERè¨ˆç®—ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆç²¾åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚")
        print("   æ¨å¥¨: pip install jiwer")
        print("")
    
    # è©•ä¾¡å®Ÿè¡Œ
    results, avg_wer, count = evaluate_asr(threshold=args.threshold)
    
    if count == 0:
        sys.exit(1)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("")
    print("=" * 60)
    print("ğŸ“Š ASR Evaluation Summary")
    print("=" * 60)
    print(f"Total Samples: {count}")
    print(f"Avg WER: {avg_wer:.3f}")
    print(f"Threshold: {args.threshold:.3f}")
    
    if avg_wer < args.threshold:
        print("âœ… Whisper accuracy within expected range.")
        status_code = 0
    else:
        print("âš ï¸  Accuracy degradation detected.")
        status_code = 1
    
    print("=" * 60)
    
    # JSONå‡ºåŠ›
    if not args.no_json:
        save_results_json(results, avg_wer, count, args.threshold)
    
    sys.exit(status_code)

if __name__ == "__main__":
    main()

